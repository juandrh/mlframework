{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.10","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error\n","from sklearn.metrics import make_scorer\n","from xgboost import XGBRegressor, DMatrix\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline            \n","import seaborn as sns\n","\n","from time import time\n","import pprint\n","import joblib\n","from functools import partial\n","\n","# Suppressing warnings because of skopt verbosity\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Skopt functions\n","from skopt import BayesSearchCV\n","from skopt.callbacks import DeadlineStopper, DeltaYStopper\n","from skopt.space import Real, Categorical, Integer\n","\n","# Model selection\n","from sklearn.model_selection import KFold\n","\n","\n","from sklearn.decomposition import TruncatedSVD\n","from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n","\n"],"metadata":{"execution":{"iopub.status.busy":"2021-08-19T09:25:56.176145Z","iopub.execute_input":"2021-08-19T09:25:56.176442Z","iopub.status.idle":"2021-08-19T09:25:57.290912Z","shell.execute_reply.started":"2021-08-19T09:25:56.176373Z","shell.execute_reply":"2021-08-19T09:25:57.290111Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["(299628, 27)\n","0 0.7094316458811298\n","1 0.7103870851582021\n","2 0.7154648928954932\n","3 0.7126914793721076\n","4 0.7118551957930397\n","0.7119660598199944 0.0020831117226571467\n"]}],"source":["df = pd.read_csv(\"../input/train_folds.csv\")\n","df_test = pd.read_csv(\"../input/test.csv\")\n","sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n","\n","df = df.drop(df[df['target'].lt(6)].index)\n","print(df.shape)\n","\n","useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n","object_cols = [col for col in useful_features if 'cat' in col]\n","numerical_cols = [col for col in useful_features if 'cont' in col]\n","df_test = df_test[useful_features]\n","\n","\n","# target encoding\n","for col in object_cols:\n","    temp_df = []\n","    temp_test_feat = None\n","    for fold in range(5):\n","        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n","        xvalid = df[df.kfold == fold].reset_index(drop=True)\n","        feat = xtrain.groupby(col)[\"target\"].agg(\"mean\")\n","        feat = feat.to_dict()\n","        xvalid.loc[:, f\"tar_enc_{col}\"] = xvalid[col].map(feat)\n","        temp_df.append(xvalid)\n","        if temp_test_feat is None:\n","            temp_test_feat = df_test[col].map(feat)\n","        else:\n","            temp_test_feat += df_test[col].map(feat)\n","    \n","    temp_test_feat /= 5\n","    df_test.loc[:, f\"tar_enc_{col}\"] = temp_test_feat\n","    df = pd.concat(temp_df)\n","\n","useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n","object_cols = [col for col in useful_features if col.startswith(\"cat\")]\n","df_test = df_test[useful_features]\n","\n","\n","# Processing categoricals with SVD encoding\n","X_seq = df[object_cols].apply(lambda x: \" \".join(list([str(y) + str(i) for i, y in enumerate(x)])), axis=1)\n","X_test_seq = df_test[object_cols].apply(lambda x: \" \".join(list([str(y) + str(i) for i, y in enumerate(x)])), axis=1)\n","\n","\n","latent_dims = 24\n","\n","svd_feats = ['svd_'+str(l) for l in range(latent_dims)]\n","vectorizer = TfidfVectorizer()\n","\n","dim_reductio = TruncatedSVD(n_components=24, random_state=0)\n","df[svd_feats] =  dim_reductio.fit_transform(vectorizer.fit_transform(X_seq))\n","df_test[svd_feats] = dim_reductio.transform(vectorizer.transform(X_test_seq))\n","\n","\n","    \n","# Processing categoricals with frequency encoding\n","object_cols = [item for item in df.columns if 'cat' in item]\n","\n","for cat in object_cols:\n","    counts = dict(df[cat].value_counts() / len(df))\n","    df[cat+'_freq'] = df[cat].replace(counts)\n","    df_test[cat+'_freq'] = df_test[cat].replace(counts)\n","\n","frequencies = [cat+'_freq' for cat in object_cols]\n","\n","\n","useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n","\n","\n","\n","\n","final_predictions = []\n","scores=[]\n","for fold in range(5):\n","    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n","    xvalid = df[df.kfold == fold].reset_index(drop=True)\n","    xtest = df_test.copy()\n","\n","    ytrain = xtrain.target\n","    yvalid = xvalid.target\n","    \n","    xtrain = xtrain[useful_features]\n","    xvalid = xvalid[useful_features]\n","\n","   \n","    # standarization\n","    scaler = preprocessing.StandardScaler()\n","    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n","    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n","    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n","\n","\n","\n","    # label encode columns \n","    ordinal_encoder = preprocessing.OrdinalEncoder()\n","    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n","    xvalid[object_cols] = ordinal_encoder.fit_transform(xvalid[object_cols])\n","    xtest[object_cols] = ordinal_encoder.fit_transform(xtest[object_cols])\n"," \n","\n","\n","    model = XGBRegressor(random_state=fold, \n","                         n_jobs=-1,\n","                         n_estimators= 4185,\n","                         tree_method='gpu_hist',\n","                         learning_rate= 0.02150695086603378,\n","                         subsample= 0.9391276589890923,\n","                         max_depth= 5,\n","                         colsample_bytree= 0.3685425845467418,\n","                         reg_lambda = 0.0025184847547236947,\n","                         reg_alpha = 3.3435424487290393,\n","                         eval_metric='rmse',\n","                         gpu_id=0,predictor='gpu_predictor',\n","                         objective='reg:squarederror')\n","    \n","    \n","    model.fit(xtrain, ytrain)\n","    preds_valid = model.predict(xvalid)\n","    test_preds = model.predict(xtest)\n","    final_predictions.append(test_preds)\n","    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n","    print(fold,rmse)\n","    scores.append(rmse)\n","    \n","print (np.mean(scores),np.std(scores))\n","\n"]},{"source":["0.7289161215950625  ordinal + stand   <br>\n","0.7359939686055645  ordinal + normalizer <br>\n","0.7339300282189536  ordinal + standard + normalizer <br>\n","0.7359933943841589  ordinal + normalizer +standard   <br>\n","0.7288775872910201  ohe + stand   <br>\n","0.7359376887794242   ohe + normalizer   <br>\n","0.7289403434752502 (ohe+ 3 ordinal) + stand   <br>\n","0.7291070689887855  poly3 (T,F) (ohe+ 1 ordinal) + stand   <br>\n","0.72914235959686  poly3 (F,F) (ohe+ 1 ordinal) + stand   <br>\n","0.728907008813998  poly2 (F,F) (ohe+ 1 ordinal) + stand   <br>\n","0.7289321289479873   poly2 (F,T) (ohe+ 1 ordinal) + stand   <br>\n","0.7289501787229472   poly2 (T,T) (ohe+ 1 ordinal) + stand   <br>\n","0.7289416327232601   poly2 (T,F) (ohe+ 1 ordinal) + stand   <br>\n","0.7288644838881868  (ohe+ 1 ordinal) + stand   <br>\n","0.7189543356528036   T_outliers+ (ohe+ 1 ordinal) + stand <br>  \n","0.7205793549092518    T_encoding + T_outliers+ (ohe+ 1 ordinal) + stand <br>\n","\n","-0.7086640526467916  opt + T_encoding + T_outliers+ (ohe+ 1 ordinal) + stand <br>\n","0.7119660598199944  opt + SVD encoding + T_encoding + T_outliers+ (ohe+ 1 ordinal) + stand <br>\n","_"],"cell_type":"markdown","metadata":{}}]}
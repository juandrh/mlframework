{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3.8.10 64-bit"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.8.10","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":["# Hyperparameter optimization  - Grid search \n","Implemented for learning purpose with no optimization libraries"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Import done\n"]}],"source":["# Importing libraries\n","import numpy as np\n","import pandas as pd\n","from time import time\n","\n","from xgboost import XGBRegressor\n","from sklearn.model_selection import KFold, StratifiedKFold\n","from sklearn.metrics import mean_squared_error\n","from sklearn import preprocessing\n","from itertools import product\n","\n","print (\"Import done\")"]},{"cell_type":"code","execution_count":94,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Data loaded\n"]}],"source":["# load data\n","\n","df = pd.read_csv(\"../input/train_folds.csv\")\n","df_test = pd.read_csv(\"../input/test.csv\")\n","sample_submission = pd.read_csv(\"../input/sample_submission.csv\")\n","\n","useful_features = [c for c in df.columns if c not in (\"id\", \"target\", \"kfold\")]\n","object_cols = [col for col in useful_features if 'cat' in col]\n","numerical_cols = [col for col in useful_features if 'cont' in col]\n","df_test = df_test[useful_features]\n","\n","print (\"Data loaded\")"]},{"cell_type":"code","execution_count":95,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of combinations: 1080\n"]},{"output_type":"execute_result","data":{"text/plain":["{'n_estimators': [1000, 500, 50],\n"," 'max_depth': [3, 5, 7, 11, 13],\n"," 'learning_rate': [1, 0.5, 0.01, 0.005],\n"," 'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n"," 'reg_alpha': [1.0, 30.0, 50.0]}"]},"metadata":{},"execution_count":95}],"source":["# set the rest of posible values for hyperparameters and a grid of combinations of them\n","\n","\n","param_names = [\"n_estimators\",\"max_depth\",\"learning_rate\",\"subsample\",\"reg_alpha\"]\n","param_values = [\n","    [1000, 500, 50],                    # \"n_estimators\"\n","    [3, 5, 7, 11, 13],                  # \"max_depth\"\n","    [1, 0.5, 0.01,0.005],               # \"learning_rate\"\n","    [.5,.6,.7,.8,.9,1.0],               # \"subsample\"\n","    [1.0,30.0,50.0]                     # \"reg_alpha\"\n","    ]\n","\n","param_combinations=list(product(*param_values))   # creates a list of all possible combinations\n","param_grid = dict(zip(param_names, param_values))\n","total_combinations = len(param_combinations)\n","print(\"Number of combinations:\" ,total_combinations)\n","param_grid"]},{"source":["## Train the model and search for best hyperparameters"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":98,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":["Round 1  /  1\n","Fold:  0 1 2 3 4 \n","\n","Mean MSE:  0.7735654713952858\n","Best MSE:  0.7735654713952858\n","Actual params:  {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 1, 'subsample': 0.5, 'reg_alpha': 1.0}\n","Best params:    {'n_estimators': 1000, 'max_depth': 3, 'learning_rate': 1, 'subsample': 0.5, 'reg_alpha': 1.0}\n","Time elapsed 0.36 min, estimated remaining time 0.00 min\n","\n"]}],"source":["num_iteration = 0 \n","best_score = np.inf  # set max error\n","best_params = {}\n","\n","#iterate every combination of params\n","for param_combination in param_combinations:   \n","    num_iteration += 1 \n","    # choose the hyperparameters for this iteration\n","    actual_params=dict(zip(param_names, param_combination))  \n","    print(\"Round\",num_iteration,\" / \",total_combinations)  \n","\n","    start_time = time()\n","    final_predictions = []\n","    scores=[]\n","    print(\"Fold: \",end=\" \")\n","\n","    # iterate in every 5 folds wich data divided\n","    for fold in range(5):     \n","        \n","        xtrain =  df[df.kfold != fold].reset_index(drop=True)\n","        xvalid = df[df.kfold == fold].reset_index(drop=True)\n","        xtest = df_test.copy()\n","\n","        ytrain = xtrain.target\n","        yvalid = xvalid.target\n","        \n","        xtrain = xtrain[useful_features]\n","        xvalid = xvalid[useful_features]\n","\n","        # categorical data -> ordinal encoder        \n","        ordinal_encoder = preprocessing.OrdinalEncoder()\n","        xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n","        xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n","        xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n","    \n","    \n","        # standarization numerical cols\n","        scaler = preprocessing.StandardScaler()\n","        xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n","        xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n","        xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n","\n","        # choose model with the hyperparameters of this round\n","        model = XGBRegressor(random_state=fold, \n","                            n_jobs=-1,               # use máx number of CPUs\n","                            tree_method='gpu_hist',  # use GPU\n","                            eval_metric='rmse',\n","                            **actual_params)         # add the actual hyperparameters\n","        \n","        # fit model and error calculation\n","        model.fit(xtrain, ytrain)\n","        preds_valid = model.predict(xvalid)\n","        rmse = mean_squared_error(yvalid, preds_valid, squared=False)        \n","        scores.append(rmse)\n","        \n","        print(fold,end =\" \") \n","\n","    time_elapsed = time() - start_time  \n","    mean_scores = np.mean(scores)\n","\n","    print (\"\\n\\nMean MSE: \",mean_scores)\n","    \n","    if (mean_scores < best_score):\n","        best_score = mean_scores\n","        best_params = actual_params.copy()\n","\n","    print (\"Best MSE: \",best_score)\n","    print (\"Actual params: \",actual_params)      \n","    print (\"Best params:   \",best_params)  \n","\n","    print((\"Time elapsed %.2f min, estimated remaining time %.2f min\\n\")% \n","            (time_elapsed/60, ((len(param_combinations)-num_iteration)*time_elapsed/60 )))\n","\n"]},{"source":["## Train and predict with best hyperparameters"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["0 0.7739620540952099\n","1 0.7716795570097768\n","2 0.773534112818326\n","3 0.7736063901363198\n","4 0.7750452429167959\n","MSE final:  0.7735654713952858\n"]}],"source":["final_predictions = []\n","scores=[]\n","for fold in range(5):     \n","        \n","    xtrain =  df[df.kfold != fold].reset_index(drop=True)\n","    xvalid = df[df.kfold == fold].reset_index(drop=True)\n","    xtest = df_test.copy()\n","\n","    ytrain = xtrain.target\n","    yvalid = xvalid.target\n","        \n","    xtrain = xtrain[useful_features]\n","    xvalid = xvalid[useful_features]\n","\n","    # categorical data -> ordinal encoder        \n","    ordinal_encoder = preprocessing.OrdinalEncoder()\n","    xtrain[object_cols] = ordinal_encoder.fit_transform(xtrain[object_cols])\n","    xvalid[object_cols] = ordinal_encoder.transform(xvalid[object_cols])\n","    xtest[object_cols] = ordinal_encoder.transform(xtest[object_cols])\n","    \n","    \n","    # standarization numerical cols\n","    scaler = preprocessing.StandardScaler()\n","    xtrain[numerical_cols] = scaler.fit_transform(xtrain[numerical_cols])\n","    xvalid[numerical_cols] = scaler.transform(xvalid[numerical_cols])\n","    xtest[numerical_cols] = scaler.transform(xtest[numerical_cols])\n","\n","    model = XGBRegressor(random_state=fold, \n","                            n_jobs=-1,               # use máx number of CPUs\n","                            tree_method='gpu_hist',  # use GPU\n","                            eval_metric='rmse',\n","                            **best_params)         # add the actual hyperparameters\n","\n","    model.fit(xtrain, ytrain)\n","    preds_valid = model.predict(xvalid)\n","    test_preds = model.predict(xtest)\n","    final_predictions.append(test_preds)\n","    rmse = mean_squared_error(yvalid, preds_valid, squared=False)\n","    print(fold,rmse)\n","    scores.append(rmse)\n","    \n","\n","print(\"MSE final: \", np.mean(scores)) "]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["preds = np.mean(np.column_stack(final_predictions), axis=1)"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[],"source":["sample_submission.target = preds\n","sample_submission.to_csv(\"submission.csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}